# Detection Agent Backlog

**Last Updated:** 2026-02-08

---

## Current Priority: Pipeline Integration & Quality Improvements

### ‚úÖ Recently Completed (This Session):
1. ‚úÖ Core ECS Field Fix (6e0ea64) - Recall restored to 62.5%
2. ‚úÖ Staging & PR Creation (479765b) - Human-in-loop workflow operational
3. ‚úÖ Mock SIEM Deployment (479765b) - Full end-to-end workflow demonstrated
4. ‚úÖ **TTP Intent Validator** (e2143e5) - Tested & operational (88% pass rate)

### üéØ Next Priorities:
1. **Integrate TTP validator into main pipeline** (after iterative validation)
2. **Improve detection quality** beyond baseline (Precision ‚â• 60%, Recall ‚â• 75%)
3. **Address remaining backlog items** (#1-6 below)

---

## Completed Items

### 0. ‚úÖ Test Log Validation - TTP Intent Verification
**Priority:** CRITICAL
**Status:** ‚úÖ **COMPLETE** (2026-02-08)
**Commit:** e2143e5 (TTP Intent Validator - Tested & Operational)

**Goal:** Ensure test payloads actually represent the threat behavior described by the TTP/indicator, not just syntactically match the generated query.

**Problem:**
- Current test payloads are generated by the same LLM that creates the query
- Risk: LLM might create circular logic (query matches log because log was designed to match query)
- Test logs may not reflect deterministic, realistic attack mechanisms
- GenAI-created payloads may lack the nuance of real-world threats

**Solution - Sub-Agent TTP Validator:**

Create a separate validation agent that:
1. **Reads the TTP description** (from MITRE ATT&CK or CTI source)
2. **Reviews the test payload** (log_entry for TP/FN cases)
3. **Validates semantic correctness:**
   - Does this log entry actually represent the described attack?
   - Are command-line arguments realistic for this tool?
   - Are file paths, timing, and user context plausible?
   - Does the evasion technique (FN) actually bypass the detection?
4. **Checks against known attack patterns:**
   - Use Google Search to find real-world examples
   - Compare against published threat reports
   - Verify command syntax matches actual malware behavior
5. **Flags unrealistic payloads:**
   - "This log entry doesn't match known Akira ransomware behavior"
   - "Command-line syntax is invalid for this tool"
   - "Evasion technique (FN) would still be detected by this query"

**Example Validation:**

```
TTP: T1490 - Inhibit System Recovery via vssadmin

Generated Test Payload (TP):
{
  "process.command_line": "vssadmin delete shadows /all /quiet"
}

TTP Validator checks:
‚úì Command syntax valid for vssadmin.exe
‚úì /all and /quiet are real vssadmin flags
‚úì This command deletes ALL shadow copies (matches TTP)
‚úì Commonly seen in Akira ransomware campaigns (Google Search confirms)

VERDICT: VALID - This payload correctly represents T1490
```

**Example Rejection:**

```
Generated Test Payload (FN - claimed evasion):
{
  "process.command_line": "vssadmin delete shadows"
}

TTP Validator checks:
‚úó Query pattern is: *delete*shadows*
‚úó This command_line WOULD match the query (contains "delete" and "shadows")
‚úó Evasion claim is false - this is NOT a false negative

VERDICT: INVALID - This would be detected, not evaded. Not a valid FN case.
```

---

## ‚úÖ Completed Implementation

**Test Results:** 17 test cases validated across 3 production rules
- ‚úÖ 15 VALID test cases (88% pass rate, high confidence)
- ‚úÖ 2 INVALID test cases detected (proof of effectiveness!)
- ‚úÖ 0 errors

**Issues Found:**
1. **Invalid FP test case** (Ransom Note rule)
   - Test payload doesn't match detection pattern
   - Actually a TN, not an FP
   - See `TTP_VALIDATOR_TEST_RESULTS.md` for details

2. **Invalid TP test case** (Shadow Copy Deletion rule)
   - WMIC command uses interactive mode (unrealistic for automated ransomware)
   - Recommendation: Use `wmic shadowcopy delete /nointeractive`
   - Research sources: MITRE ATT&CK, Microsoft docs, The DFIR Report (Conti ransomware)

**Files Created:**
- ‚úÖ `detection_agent/tools/ttp_intent_validator.py` (async validator using Gemini 2.5 Pro)
- ‚úÖ `detection_agent/prompts/ttp_validator_prompt.md` (296 lines, comprehensive validation criteria)
- ‚úÖ `scripts/test_ttp_validator.py` (production rule testing)
- ‚úÖ `scripts/demo_ttp_validation.py` (demonstration without API calls)
- ‚úÖ `TTP_VALIDATOR_TEST_RESULTS.md` (detailed findings and analysis)
- ‚úÖ `ttp_validation_results.json` (structured validation results)

**Next Steps:**
1. Integrate TTP validator into main pipeline after step 3.5 (iterative validation)
2. Add regeneration loop for invalid payloads
3. Update GitHub workflows to include TTP validation step

---

## Original Implementation Plan (For Reference)

**Implementation:**

1. **Create `detection_agent/tools/ttp_validator.py`:**
   - Sub-agent using Gemini 2.5 Pro (higher reasoning for validation)
   - Takes: TTP ID, TTP description, test payload, detection query
   - Returns: Validation result (VALID/INVALID with explanation)

2. **Integration Point:**
   - Run AFTER iterative validation
   - Before LLM judge (pre-filter bad tests)
   - If test payload fails TTP validation ‚Üí regenerate with feedback

3. **Validation Criteria:**
   - **TP cases:** Must realistically represent the attack
   - **FN cases:** Must genuinely evade detection (critical check)
   - **FP cases:** Must be legitimate activity that could false alarm
   - **TN cases:** Must be baseline normal activity

4. **Research Sources:**
   - MITRE ATT&CK procedure examples
   - Threat reports (search for "Akira ransomware vssadmin")
   - Tool documentation (man pages, Microsoft docs)
   - Security vendor detections (Elastic, Splunk)

**Example Workflow:**

```
Generate Rules ‚Üí Iterative Validation ‚Üí TTP Validator ‚Üí LLM Judge
                                              ‚Üì
                                        Invalid payloads
                                              ‚Üì
                                        Regenerate with feedback
```

**Files to create:**
- `detection_agent/tools/ttp_validator.py` - Sub-agent for TTP validation
- `detection_agent/prompts/ttp_validator_prompt.md` - Validation criteria
- `detection_agent/tools/attack_pattern_research.py` - Research real attack patterns

**Expected Impact:**
- Catch "too easy" test cases that always match
- Identify false FN claims (evasions that don't actually evade)
- Ensure test payloads match real-world attack mechanisms
- Improve confidence in detection quality scores

---

## Backlog (Active Items)

### 1. Workflow Timing Optimization
**Priority:** Medium
**Status:** Pending

**Tasks:**
- Clean up workflow sleep timings
- Set to 1 second sleeps to prevent failed messages
- Review all `INTER_AGENT_DELAY` and `asyncio.sleep()` calls
- Balance between rate limiting and performance

**Files to update:**
- `detection_agent/agent.py` - INTER_AGENT_DELAY
- `detection_agent/tools/iterative_validator.py` - inter_agent_delay
- `.github/workflows/*.yml` - any hardcoded delays

---

### 2. Support for Detection Engineer Uploads (SPL/YML)
**Priority:** High
**Status:** Pending

**Goal:** Allow detection engineers to upload existing correlation searches in SPL or YML format and treat them the same as threat intelligence.

**Tasks:**
1. **File Format Support:**
   - Extend `load_cti_files.py` to handle `.spl` (Splunk) and `.yml` (YAML) detection rules
   - Parse existing detection logic and extract:
     - Detection patterns (what to look for)
     - Field mappings (source ‚Üí ECS translation)
     - Known false positives
     - Test cases (if embedded)

2. **Translation Logic:**
   - SPL ‚Üí Lucene query translation
   - YAML (Sigma/custom) ‚Üí Lucene query translation
   - Map Splunk field names to ECS equivalents (e.g., `sourcetype` ‚Üí `event.dataset`)

3. **Intelligence Extraction:**
   - Treat detection rules as "threat intelligence"
   - Extract TTPs from rule descriptions/tags
   - Use existing detection logic as hints for query construction
   - Preserve test cases from uploaded rules

4. **Example Workflow:**
   ```
   User uploads: my_detection.spl
   Content: "index=windows sourcetype=WinEventLog:Security EventCode=4688 CommandLine=*vssadmin*delete*"

   Agent:
   1. Parses SPL ‚Üí extracts search terms (EventCode=4688, CommandLine pattern)
   2. Maps to ECS ‚Üí event.code:4688, process.command_line:*vssadmin*delete*
   3. Generates Lucene query with core ECS fields
   4. Creates test cases based on SPL logic
   ```

**Files to create/modify:**
- `detection_agent/tools/load_cti_files.py` - add SPL/YML parsing
- `detection_agent/tools/parse_spl.py` - SPL parser (new)
- `detection_agent/tools/parse_detection_yaml.py` - YAML detection parser (new)
- `detection_agent/tools/field_mapper.py` - Splunk‚ÜíECS, other‚ÜíECS mapping (new)
- `detection_agent/prompts/detection_generator.md` - update to handle uploaded detections
- `cti_src/README.md` - document supported formats

**Dependencies:**
- Consider using `splunk-sdk` or `pyparsing` for SPL parsing
- YAML parsing already supported (PyYAML)

**Testing:**
- Upload sample SPL detection ‚Üí verify Lucene translation
- Upload Sigma rule ‚Üí verify no duplicate effort
- Upload custom YAML ‚Üí verify field mapping

---

### 3. Setup & Bootstrap Script
**Priority:** Medium
**Status:** Pending

**Tasks:**
1. Create `scripts/setup.sh` (or `setup.py` for cross-platform)
   - Check Python version (3.10+)
   - Install dependencies from requirements.txt
   - Verify GCP authentication
   - Verify GitHub CLI installed
   - Download ECS schema cache
   - Create necessary directories (cti_src, generated, session_results)
   - Set executable permissions on scripts
   - Validate environment variables

2. Create bootstrap checklist script
   - Pre-flight checks before running agent
   - Verify all tools available (yq, jq, docker, gh)
   - Test GCP/GitHub connectivity

3. Error messages and remediation
   - If GCP auth fails ‚Üí "Run: gcloud auth login"
   - If gh not found ‚Üí "Install GitHub CLI: brew install gh"
   - If Docker not running ‚Üí "Start Docker Desktop"

**Files to create:**
- `scripts/setup.sh` or `scripts/setup.py`
- `scripts/preflight_check.sh`
- `SETUP.md` - setup instructions

---

### 4. Documentation Updates
**Priority:** Medium
**Status:** Pending

**Tasks:**
1. **README.md:**
   - Add setup instructions (link to SETUP.md)
   - Document supported file formats (PDF, DOCX, TXT, MD, SPL, YML)
   - Add architecture diagram (mermaid or ASCII)
   - Document workflow triggers (manual, push, schedule)
   - Add troubleshooting section
   - Link to ITERATIVE_VALIDATION_SUCCESS.md

2. **cti_src/README.md:**
   - Explain what CTI files to place here
   - Document supported formats
   - Provide examples
   - Explain how uploaded SPL/YML is processed

3. **CONTRIBUTING.md:**
   - How to add new validation tools
   - How to modify generator prompts
   - How to test locally vs in GitHub Actions

**Files to create/update:**
- `README.md` - complete overhaul
- `cti_src/README.md` - new file
- `CONTRIBUTING.md` - new file

---

### 5. Logging & Exception Handling Improvements
**Priority:** High
**Status:** Pending

**Goal:** Ensure robust logging and exception handling throughout the entire agent pipeline, including sub-agents and iterative workflows.

**Tasks:**
1. **Centralized Logging:**
   - Create `detection_agent/utils/logger.py`
   - Use Python `logging` module with structured logs
   - Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
   - Log to file: `session_results/agent_run_<timestamp>.log`
   - Log format: `[TIMESTAMP] [LEVEL] [COMPONENT] Message`

2. **Exception Handling:**
   - Wrap all API calls in try/except with specific exceptions
   - Distinguish between:
     - **Retryable errors:** ResourceExhausted, 429, 500, 503 ‚Üí retry with backoff
     - **Fatal errors:** Invalid API key, quota exceeded, malformed response ‚Üí fail fast
     - **Validation errors:** Invalid Lucene syntax, unknown field ‚Üí trigger refinement
   - Log stack traces for debugging
   - Return user-friendly error messages

3. **Retry Logic Audit:**
   - Review all `generate_with_retry()` calls
   - Ensure exponential backoff is consistent
   - Add jitter to prevent thundering herd
   - Log retry attempts with delay duration

4. **Sub-Agent Error Handling:**
   - `research_ecs_field.py` - handle API failures gracefully
   - `iterative_validator.py` - handle validation failures without crashing
   - Propagate errors up with context

5. **Workflow-Level Error Handling:**
   - GitHub Actions workflow failures should output actionable logs
   - `set -e` for fail-fast, but catch errors and log before exit
   - Upload logs as artifacts even on failure

**Files to modify:**
- `detection_agent/utils/logger.py` - new centralized logger
- `detection_agent/agent.py` - add logging to all steps
- `detection_agent/tools/*.py` - add exception handling to all tools
- `detection_agent/tools/research_ecs_field.py` - handle API errors
- `detection_agent/tools/iterative_validator.py` - handle validation errors
- `.github/workflows/*.yml` - upload logs on failure

**Example Logging:**
```python
import logging
from detection_agent.utils.logger import setup_logger

logger = setup_logger(__name__)

try:
    result = await generate_with_retry(...)
    logger.info(f"Generated {len(result['rules'])} rules")
except ResourceExhausted as e:
    logger.warning(f"Rate limited, retrying in {delay}s: {e}")
    await asyncio.sleep(delay)
except InvalidResponse as e:
    logger.error(f"LLM returned invalid response: {e}")
    raise
```

---

### 6. Refinement Solution-Wide Retry Logic
**Priority:** High
**Status:** Pending

**Goal:** Ensure retry logic is consistent across all agents, sub-agents, and tools.

**Tasks:**
1. **Retry Configuration Audit:**
   - Review `AGGRESSIVE_RETRY_CONFIG` and `FLASH_RETRY_CONFIG`
   - Ensure all API calls use appropriate retry config
   - Document retry strategies in code comments

2. **Sub-Agent Retry:**
   - `research_ecs_field.py` - add retry for API calls
   - `iterative_validator.py` - retry on transient failures

3. **Workflow-Level Retry:**
   - GitHub Actions: use `continue-on-error` where appropriate
   - Add `max_retries` parameter to workflow dispatch

4. **Rate Limit Handling:**
   - Detect ResourceExhausted early
   - Log quota usage (requests per minute)
   - Suggest delay duration based on quota limits

**Files to modify:**
- `detection_agent/agent.py` - audit all retry configs
- `detection_agent/tools/research_ecs_field.py` - add retry logic
- `.github/workflows/*.yml` - add workflow retry options

---

### 7. Detection Quality Improvements
**Priority:** High
**Status:** Pending

**Goal:** Improve detection precision and recall to meet quality thresholds without losing TTP intent or compromising test case realism.

**Current Metrics (Akira Ransomware Rules):**
- **Precision:** 45.5% (current) ‚Üí Target: ‚â• 60%
- **Recall:** 62.5% (current) ‚Üí Target: ‚â• 70%
- **LLM Quality Scores:** 0.93-0.97 (meeting ‚â•0.75 threshold ‚úÖ)
- **TTP Validation:** 88% initial pass rate (100% after fixes)

**Tasks:**

1. **Analyze False Positives (6 FP cases):**
   - Review each FP test case to identify why benign activity triggered
   - Common causes:
     - Detection query too broad (overly generic wildcards)
     - Missing filter_legitimate conditions
     - Core ECS fields not specific enough
   - Proposed fixes:
     - Add more specific field combinations (e.g., process.parent.name)
     - Add exclusion filters for known benign processes
     - Tighten wildcard patterns (use anchors where appropriate)

2. **Analyze False Negatives (3 FN cases):**
   - Review each FN evasion technique to validate realism
   - Check if evasion is:
     - **Realistic:** Would attackers actually use this technique?
     - **Documentable:** Is this a known bypass from threat intel?
     - **Addressable:** Can detection logic be broadened safely?
   - Proposed fixes:
     - Broaden detection patterns to cover variants
     - Add alternate field combinations (e.g., original_file_name)
     - Research documented evasions (MITRE, threat reports)

3. **Tune Detection Queries:**
   - **For Precision:** Add specificity without losing coverage
     - Example: `process.command_line:*wmic*shadowcopy*delete*` AND `process.parent.name:cmd.exe`
     - Example: Add `event.action:process_start` to reduce noise
   - **For Recall:** Cover documented attack variations
     - Example: Add alternate commands (vssadmin, wbadmin, bcdedit for T1490)
     - Example: Cover both interactive and non-interactive modes

4. **Validate with TTP Intent Validator:**
   - Re-run TTP validator after each tuning iteration
   - Ensure new test cases maintain 100% pass rate
   - Prevent circular logic (query matching log because log matches query)

5. **Iterative Improvement Workflow:**
   ```
   1. Identify FP/FN cases with low confidence
   2. Research real-world attack patterns for those TTPs
   3. Propose query refinements OR test case updates
   4. Run TTP validator ‚Üí ensure test case realism
   5. Run integration test ‚Üí measure new precision/recall
   6. Repeat until thresholds met (Precision ‚â• 60%, Recall ‚â• 70%)
   ```

6. **Quality Gates:**
   - **Do NOT sacrifice:**
     - TTP alignment (test cases must match real attacks)
     - Test case realism (validated by TTP intent validator)
     - LLM quality scores (must stay ‚â•0.75)
   - **Acceptable trade-offs:**
     - Slightly lower recall if it significantly improves precision
     - More complex queries if they reduce false positives
     - Additional ECS fields if they improve accuracy

**Files to modify:**
- `production_rules/*.yml` - tune detection queries
- `detection_agent/prompts/detection_generator.md` - add tuning guidance
- `detection_agent/prompts/evaluator.md` - improve FP/FN generation
- Integration test results ‚Üí track improvement trends

**Success Criteria:**
- Precision ‚â• 60% (max 40% false positives)
- Recall ‚â• 70% (catch at least 70% of attacks)
- TTP validation: 100% valid test cases maintained
- LLM quality scores: ‚â• 0.75 maintained

**Timeline:**
- Iteration 1: Analyze current FP/FN cases (30 min)
- Iteration 2: Tune 1 rule, validate, test (1 hour)
- Iteration 3: Apply learnings to remaining rules (2 hours)
- Iteration 4: Final validation and documentation (30 min)

**Documentation:**
- Create `docs/milestones/QUALITY_IMPROVEMENT_CYCLE.md` after completion
- Document tuning patterns for future rule generation
- Update SESSION_SUMMARY.md with final metrics

---

### 8. Production-Ready Workflow Naming
**Priority:** Medium
**Status:** Pending

**Goal:** Rename "End-to-End Detection Pipeline Test" to production-appropriate name and update all references.

**Current Issues:**
- Workflow name "End-to-End Detection Pipeline Test" sounds like development/testing
- Repository is now production-ready but naming suggests it's still in test phase
- Need consistent, professional naming across all workflows

**Proposed Changes:**

1. **Rename Workflow:**
   - Current: "End-to-End Detection Pipeline Test"
   - Proposed: "Detection Pipeline - Full Orchestration" or "Automated Detection Engineering Pipeline"
   - File: `.github/workflows/end-to-end-test.yml`

2. **Update All References:**
   - README.md - workflow descriptions and diagrams
   - END_TO_END_TEST.md - document title and references
   - BACKLOG.md - this file
   - SESSION_SUMMARY.md - workflow mentions
   - Any other documentation

3. **Review All Workflow Names for Production Readiness:**
   - ‚úì "Generate Detection Rules from CTI" - good
   - ‚úì "Integration Test - Elasticsearch" - good
   - ‚úì "Mock SIEM Deployment" - good
   - ‚úì "Cleanup Stale Artifacts" - good
   - ‚ö†Ô∏è  "End-to-End Detection Pipeline Test" - needs update

**Files to modify:**
- `.github/workflows/end-to-end-test.yml` - workflow name
- `README.md` - all references and diagrams
- `END_TO_END_TEST.md` - document title
- `BACKLOG.md` - this entry when complete
- `SESSION_SUMMARY.md` - workflow references

**Success Criteria:**
- All workflow names sound production-ready
- No references to "test" unless actually for testing
- Documentation consistently uses new name
- No broken links or references

---

## Completed Tasks

### ‚úÖ Iterative Validation System (Stage 3.5)
- Built ECS schema loader, validator, and research sub-agent
- Implemented 3-iteration refinement loop
- Integrated into main agent pipeline
- **Documented:** ITERATIVE_VALIDATION_SUCCESS.md

### ‚úÖ Integration Testing with Docker Elasticsearch
- Ephemeral ELK stack in GitHub Actions
- Test payload execution and metrics calculation
- Precision/Recall/F1 evaluation

### ‚úÖ Core ECS Field Prompt Fix
- Updated generator prompt to mandate event.category and event.type
- Added CRITICAL section emphasizing core ECS categorization
- Updated all examples to include core fields

---

## Notes

- All backlog items are post-current-fix tasks
- Current priority: Test prompt fix ‚Üí ensure recall improves
- User feedback: "good job" - continue with testing and iteration
